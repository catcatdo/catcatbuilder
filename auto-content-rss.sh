#!/bin/zsh
# CatCat Builder ìë™ ì½˜í…ì¸  ìƒì„± ìŠ¤í¬ë¦½íŠ¸ (RSS ê°œì„  ë²„ì „) - macOS í˜¸í™˜

set -euo pipefail

REPO_DIR="$HOME/.openclaw/workspace/catcatbuilder"
DATE=$(date '+%Y-%m-%d')
DATETIME=$(date '+%Y%m%d_%H%M')
LOG_FILE="$REPO_DIR/.auto_content/log_$DATETIME.txt"
RSS_TMP_FILE="/tmp/reddit_feed.xml"
RSS_TITLE_TMP_FILE="/tmp/reddit_title.txt"

mkdir -p "$REPO_DIR/.auto_content"

echo "[$DATETIME] ìë™ ì½˜í…ì¸  ìƒì„± ì‹œì‘" | tee -a "$LOG_FILE"

cd "$REPO_DIR"

# Git ì„¤ì •
git config --local user.name "ë¦´ë¦¬ (ìë™í™”)" 2>/dev/null || true
git config --local user.email "lily@auto.build" 2>/dev/null || true

# GitHub í† í° ë¡œë“œ
if [ -f "$REPO_DIR/.env" ]; then
    source "$REPO_DIR/.env"
fi

# ===== 1. Reddit RSSì—ì„œ ì¸ê¸° ê¸€ ê°€ì ¸ì˜¤ê¸° =====
echo "ğŸ” Reddit RSS ì¡°ì‚¬ ì¤‘..." | tee -a "$LOG_FILE"

RSS_URLS=(
    "https://www.reddit.com/r/technology/top/.rss?t=day"
    "https://www.reddit.com/r/programming/top/.rss?t=day"
    "https://www.reddit.com/r/apple/top/.rss?t=day"
    "https://www.reddit.com/r/gadgets/top/.rss?t=day"
)

RSS_URL=${RSS_URLS[$RANDOM % ${#RSS_URLS[@]}]}
echo "ì„ íƒëœ RSS: $RSS_URL" | tee -a "$LOG_FILE"

# RSS ê°€ì ¸ì˜¤ê¸°
if ! curl -fsSL -A "Mozilla/5.0" "$RSS_URL" -o "$RSS_TMP_FILE" 2>/dev/null; then
    echo "âš ï¸ RSS ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨, fallback ì œëª© ì‚¬ìš©" | tee -a "$LOG_FILE"
fi

# RSS title íŒŒì‹± (ìš”êµ¬ì‚¬í•­: grep/sed ì‚¬ìš©)
if [ -s "$RSS_TMP_FILE" ]; then
    grep -oE '<title><!\[CDATA\[[^]]+\]\]></title>|<title>[^<]+</title>' "$RSS_TMP_FILE" \
        | sed -E 's#<title><!\[CDATA\[##; s#\]\]></title>##; s#<title>##; s#</title>##' \
        | sed 's/^ *//; s/ *$//' \
        | sed '/^$/d' \
        | sed '/^r\//d' \
        | sed '/^search results/d' \
        | sed '/^comments$/d' \
        | head -1 > "$RSS_TITLE_TMP_FILE" || true
fi

# ë™ì  fallback (ê³ ì • ì œëª© ê¸ˆì§€)
FALLBACK_TITLE="Reddit ê¸°ìˆ  ì´ìŠˆ ë¸Œë¦¬í•‘ $(date '+%mì›” %dì¼ %Hì‹œ')"
REDDIT_TITLE=$(cat "$RSS_TITLE_TMP_FILE" 2>/dev/null || echo "$FALLBACK_TITLE")
[ -z "${REDDIT_TITLE// }" ] && REDDIT_TITLE="$FALLBACK_TITLE"

echo "ì„ ì •ëœ ì£¼ì œ: $REDDIT_TITLE" | tee -a "$LOG_FILE"

# ===== ì¤‘ë³µ ì²´í¬: ìµœê·¼ 24ì‹œê°„ ë‚´ ë™ì¼ ì œëª© =====
echo "ğŸ” posts.json ì¤‘ë³µ ì²´í¬ ì¤‘..." | tee -a "$LOG_FILE"

SKIP_POST=0
DUPLICATE_CHECK_RESULT=$(REDDIT_TITLE="$REDDIT_TITLE" python3 <<'PYTHON_DUP_CHECK'
import datetime as dt
import json
import os
import re
import sys


def parse_post_time(post: dict) -> dt.datetime | None:
    # ìë™ ìƒì„± slug: auto-post-YYYYMMDD-HHMM
    slug = str(post.get("slug", "")).strip()
    m = re.match(r"^auto-post-(\d{8})-(\d{4})$", slug)
    if m:
        try:
            return dt.datetime.strptime(m.group(1) + m.group(2), "%Y%m%d%H%M")
        except ValueError:
            pass

    # created_at / datetime í™•ì¥ í•„ë“œê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
    for key in ("created_at", "datetime", "published_at"):
        raw = post.get(key)
        if not raw:
            continue
        text = str(raw).strip().replace("Z", "+00:00")
        try:
            parsed = dt.datetime.fromisoformat(text)
            if parsed.tzinfo is not None:
                parsed = parsed.astimezone().replace(tzinfo=None)
            return parsed
        except ValueError:
            continue

    # ê¸°ë³¸ date í•„ë“œ(YYYY-MM-DD)ëŠ” ìì •ìœ¼ë¡œ ê°„ì£¼
    date_text = str(post.get("date", "")).strip()
    if date_text:
        try:
            return dt.datetime.strptime(date_text, "%Y-%m-%d")
        except ValueError:
            return None
    return None


title = os.environ.get("REDDIT_TITLE", "").strip()
if not title:
    print("OK|empty-title")
    sys.exit(0)

with open("posts.json", "r", encoding="utf-8") as f:
    posts = json.load(f).get("posts", [])

now = dt.datetime.now()
window = dt.timedelta(hours=24)
target = title.casefold()

for post in posts:
    existing_title = str(post.get("title", "")).strip()
    if existing_title.casefold() != target:
        continue

    posted_at = parse_post_time(post)
    if posted_at is None:
        continue

    age = now - posted_at
    if dt.timedelta(0) <= age <= window:
        print(f"SKIP|{existing_title}|{posted_at.isoformat(timespec='minutes')}")
        sys.exit(0)

print("OK|no-duplicate")
PYTHON_DUP_CHECK
)

if [[ "$DUPLICATE_CHECK_RESULT" == SKIP\|* ]]; then
    SKIP_POST=1
    EXISTING_TITLE=$(echo "$DUPLICATE_CHECK_RESULT" | cut -d'|' -f2)
    EXISTING_TIME=$(echo "$DUPLICATE_CHECK_RESULT" | cut -d'|' -f3)
    echo "â­ï¸ ìµœê·¼ 24ì‹œê°„ ë‚´ ë™ì¼ ì œëª© ë°œê²¬, ê¸€ ìƒì„± ìŠ¤í‚µ: '$EXISTING_TITLE' ($EXISTING_TIME)" | tee -a "$LOG_FILE"
else
    echo "âœ… ì¤‘ë³µ ì—†ìŒ, ê¸€ ìƒì„±ì„ ì§„í–‰í•©ë‹ˆë‹¤." | tee -a "$LOG_FILE"
fi

# ===== 2. ë””ì‹œì¸ì‚¬ì´ë“œ ì¡°ì‚¬ =====
echo "ğŸ” ë””ì‹œì¸ì‚¬ì´ë“œ ì¡°ì‚¬ ì¤‘..." | tee -a "$LOG_FILE"
DC_TOPIC="ì¶”ì„ MANHWA (ì¶”ì²œ 2046)"
echo "ë””ì‹œ ì£¼ì œ: $DC_TOPIC" | tee -a "$LOG_FILE"

# ===== 3. GitHub Issue ë“±ë¡ =====
echo "ğŸ“ GitHub Issue ë“±ë¡ ì¤‘..." | tee -a "$LOG_FILE"

if [ -f "$REPO_DIR/.env" ]; then
    source "$REPO_DIR/.env"
fi

if command -v gh &> /dev/null && [ -n "${GH_TOKEN:-}" ]; then
    gh issue create \
        --repo catcatdo/catcatbuilder \
        --title "[ë””ì‹œ] $DC_TOPIC" \
        --body "**ê°¤ëŸ¬ë¦¬:** HIT ê°¤ëŸ¬ë¦¬

**ì£¼ì œ:** $DC_TOPIC

**ì¶”ì²œìˆ˜:** 2046

**ìš”ì•½:**
ì¶”ì„ ì—°íœ´ ê¸°ê°„ ë””ì‹œì¸ì‚¬ì´ë“œì—ì„œ í° í™”ì œê°€ ëœ MANHWA ì½˜í…ì¸ .
ìœ ë¨¸ì™€ ê³µê°ëŒ€ë¥¼ ìê·¹í•˜ëŠ” ë‚´ìš©ìœ¼ë¡œ ë§ì€ ì¶”ì²œì„ ë°›ìŒ.

**ë§í¬:** https://gall.dcinside.com/board/lists/?id=hit

**ìˆ˜ì§‘ ì‹œê°„:** $DATETIME" \
        2>> "$LOG_FILE" && echo "âœ… Issue ìƒì„± ì™„ë£Œ" | tee -a "$LOG_FILE" || echo "âš ï¸ Issue ìƒì„± ì‹¤íŒ¨ (ì´ë¯¸ ìˆê±°ë‚˜ ì˜¤ë¥˜)" | tee -a "$LOG_FILE"
else
    echo "âš ï¸ GitHub CLI ë¯¸ì„¤ì¹˜ ë˜ëŠ” í† í° ì—†ìŒ" | tee -a "$LOG_FILE"
fi

# ===== 4. ë¸”ë¡œê·¸ ê¸€ ì‘ì„± =====
echo "âœï¸ ë¸”ë¡œê·¸ ê¸€ ì‘ì„± ì¤‘..." | tee -a "$LOG_FILE"

if [ "$SKIP_POST" -eq 1 ]; then
    echo "â­ï¸ ë¸”ë¡œê·¸ ê¸€ ìƒì„± ë‹¨ê³„ ìŠ¤í‚µ ì™„ë£Œ" | tee -a "$LOG_FILE"
else
    MAX_ID=$(grep -o '"id": [0-9]*' posts.json | grep -o '[0-9]*' | sort -n | tail -1)
    NEW_ID=$((MAX_ID + 1))
    SLUG="auto-post-$(date +%Y%m%d-%H%M)"

    echo "ìƒˆ ê¸€ ID: $NEW_ID" | tee -a "$LOG_FILE"

    # ê¹¨ì§€ì§€ ì•ŠëŠ” Unsplash ì›ë³¸ URL ëª©ë¡
    UNSPLASH_URLS=(
        "https://images.unsplash.com/photo-1518770660439-4636190af475?auto=format&fit=crop&w=1600&q=80"
        "https://images.unsplash.com/photo-1451187580459-43490279c0fa?auto=format&fit=crop&w=1600&q=80"
        "https://images.unsplash.com/photo-1519389950473-47ba0277781c?auto=format&fit=crop&w=1600&q=80"
        "https://images.unsplash.com/photo-1504384308090-c894fdcc538d?auto=format&fit=crop&w=1600&q=80"
    )

    IMAGE_URL=${UNSPLASH_URLS[$RANDOM % ${#UNSPLASH_URLS[@]}]}
    echo "ğŸ–¼ï¸ ì´ë¯¸ì§€ URL ì„ íƒ: $IMAGE_URL" | tee -a "$LOG_FILE"

    echo "ğŸ“ posts.json ì—…ë°ì´íŠ¸ ì¤‘..." | tee -a "$LOG_FILE"

    REDDIT_TITLE="$REDDIT_TITLE" DATE="$DATE" IMAGE_URL="$IMAGE_URL" SLUG="$SLUG" NEW_ID="$NEW_ID" python3 <<'PYTHON_SCRIPT'
import json
import os
import sys


def section_exact(base: str, target: int) -> str:
    text = base.strip()
    if len(text) >= target:
        return text[:target]
    filler = " ì´ íë¦„ì„ ì‹¤ì œ ì„œë¹„ìŠ¤ ì§€í‘œì™€ íŒ€ ìš´ì˜ ê´€ì ì—ì„œ í™•ì¸í•˜ë©´ íŒë‹¨ì˜ ì •í™•ë„ê°€ ë†’ì•„ì§„ë‹¤."
    while len(text) < target:
        need = target - len(text)
        text += filler[:need]
    return text


def make_excerpt(title: str) -> str:
    hook = f"ì˜¤ëŠ˜ Reddit 1ìœ„ '{title}'ë¥¼ ì½”ë“œì™€ ì‚¬ë¡€ë¡œ 5ë¶„ ìš”ì•½: ë‹¹ì¥ ì ìš© ê°€ëŠ¥í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸ê¹Œì§€ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤."
    if len(hook) > 110:
        return hook[:107].rstrip() + "..."
    return hook


def build_content(title: str) -> str:
    intro = section_exact(
        f"## ì¸íŠ¸ë¡œ\n\nì˜¤ëŠ˜ Reddit ìƒìœ„ í”¼ë“œì—ì„œ ê°€ì¥ ë¹ ë¥´ê²Œ í™•ì‚°ëœ ì£¼ì œëŠ” '{title}'ë‹¤. ë‹¨ìˆœ í™”ì œì„±ìœ¼ë¡œ ëë‚˜ëŠ” ì´ìŠˆê°€ ì•„ë‹ˆë¼, ì œí’ˆ ì˜ì‚¬ê²°ì •Â·ê°œë°œ ìš°ì„ ìˆœìœ„Â·íŒ€ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ê¹Œì§€ ì§ì ‘ ì˜í–¥ì„ ì£¼ëŠ” ì‹ í˜¸ë¼ëŠ” ì ì´ í•µì‹¬ì´ë‹¤. ì´ ê¸€ì€ 'ì™œ ì§€ê¸ˆ ì´ ì´ìŠˆë¥¼ ì½ì–´ì•¼ í•˜ëŠ”ê°€'ë¥¼ ì§§ê²Œ ì •ë¦¬í•˜ê³ , ë°”ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê¸°ìˆ ì  ëŒ€ì‘ ì „ëµì„ ì½”ë“œ ë‹¨ìœ„ë¡œ ì—°ê²°í•œë‹¤.",
        200,
    )

    body = section_exact(
        f"## ë³¸ë¬¸ ë¶„ì„\n\n'{title}' ì´ìŠˆë¥¼ ì‹¤ë¬´ ê´€ì ì—ì„œ ë¶„í•´í•˜ë©´ ì„¸ ê°€ì§€ ì¶•ì´ ë³´ì¸ë‹¤. ì²«ì§¸ëŠ” ì‚¬ìš©ì ê¸°ëŒ€ì¹˜ì˜ ìƒìŠ¹ì´ë‹¤. ìƒˆë¡œìš´ ê¸°ìˆ ì´ë‚˜ ì •ì±… ë³€í™”ê°€ ë“±ì¥í•˜ë©´ ì‚¬ìš©ìëŠ” ì¦‰ì‹œ ì²´ê° ê°€ëŠ¥í•œ ê°œì„ ì„ ì›í•œë‹¤. ë‘˜ì§¸ëŠ” ê°œë°œ ë¹„ìš© êµ¬ì¡°ì˜ ì¬í¸ì´ë‹¤. ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ì„ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë©´ ê¸°ëŠ¥ ì¶”ê°€ ì†ë„ëŠ” ë‚˜ì™€ë„ í’ˆì§ˆ ì§€í‘œê°€ ë¬´ë„ˆì§€ê¸° ì‰½ë‹¤. ì…‹ì§¸ëŠ” ìš´ì˜ ë¦¬ìŠ¤í¬ë‹¤. ì´ˆê¸° ë°˜ì‘ë§Œ ë³´ê³  ë¹ ë¥´ê²Œ ë°°í¬í•˜ë©´ ì¥ì• Â·ë³´ì•ˆÂ·ê·œì œ ëŒ€ì‘ì´ ë’¤ëŠ¦ê²Œ ë”°ë¼ì˜¤ë©° ê²°êµ­ íŒ€ ì „ì²´ì˜ ì»¨í…ìŠ¤íŠ¸ ìŠ¤ìœ„ì¹­ ë¹„ìš©ì´ ì»¤ì§„ë‹¤.\n\nì‹¤í–‰ ì „ëµì€ 'ì‘ê²Œ ê²€ì¦í•˜ê³ , ëª…í™•íˆ ê³„ì¸¡í•˜ê³ , ë¹ ë¥´ê²Œ íšŒê³ 'ë¡œ ì •ë¦¬í•  ìˆ˜ ìˆë‹¤. ë¨¼ì € ê°€ì„¤ì„ ë¬¸ì¥ í•˜ë‚˜ë¡œ ê³ ì •í•œë‹¤. ì˜ˆ: 'ì´ë²ˆ ë³€ê²½ì€ ì‹ ê·œ ì‚¬ìš©ì 1ì£¼ì°¨ ë¦¬í…ì…˜ì„ 3%p ì˜¬ë¦°ë‹¤.' ë‹¤ìŒìœ¼ë¡œ ì‹¤í—˜ ë²”ìœ„ë¥¼ ì œí•œí•œë‹¤. ì „ì²´ íŠ¸ë˜í”½ì— ì¦‰ì‹œ ì ìš©í•˜ì§€ ë§ê³ , ì„¸ê·¸ë¨¼íŠ¸ ê¸°ë°˜ ë¡¤ì•„ì›ƒìœ¼ë¡œ ì´ìƒ ì§•í›„ë¥¼ ê´€ì°°í•œë‹¤. ë§ˆì§€ë§‰ìœ¼ë¡œ ê¸°ìˆ  ì§€í‘œì™€ ë¹„ì¦ˆë‹ˆìŠ¤ ì§€í‘œë¥¼ ê°™ì€ ëŒ€ì‹œë³´ë“œì—ì„œ ë³¸ë‹¤. ë°°í¬ ì„±ê³µë¥ Â·ì˜¤ë¥˜ìœ¨Â·ì‘ë‹µì‹œê°„ë§Œ ë³´ë©´ ì ˆë°˜ì˜ ì§„ì‹¤ë§Œ ë³´ê²Œ ëœë‹¤. ì „í™˜ìœ¨Â·ì´íƒˆë¥ Â·ë¬¸ì˜ëŸ‰ì„ í•¨ê»˜ ë¬¶ì–´ì•¼ ì‹¤ì œ ê°€ì¹˜ê°€ ë“œëŸ¬ë‚œë‹¤.\n\nì•„ë˜ ì½”ë“œëŠ” ì´ìŠˆ ëŒ€ì‘ì˜ ìµœì†Œ ë£¨í”„ë¥¼ ìë™í™”í•˜ëŠ” ì˜ˆì‹œë‹¤. í¬ì¸íŠ¸ëŠ” ë¡œê·¸ë¥¼ 'ë‚¨ê¸´ë‹¤'ê°€ ì•„ë‹ˆë¼, ì˜ì‚¬ê²°ì • ê°€ëŠ¥í•œ í˜•íƒœë¡œ 'ì •ê·œí™”í•œë‹¤'ëŠ” ë° ìˆë‹¤.\n\n```python\nfrom dataclasses import dataclass\n\n@dataclass\nclass ExperimentSignal:\n    ctr_delta: float\n    error_rate: float\n    p95_ms: int\n\ndef should_roll_forward(signal: ExperimentSignal) -> bool:\n    healthy_perf = signal.p95_ms < 900 and signal.error_rate < 0.01\n    business_gain = signal.ctr_delta >= 0.03\n    return healthy_perf and business_gain\n\nsignal = ExperimentSignal(ctr_delta=0.041, error_rate=0.006, p95_ms=740)\nprint(\"roll_forward\" if should_roll_forward(signal) else \"hold\")\n```\n\nì‹¤ë¬´ì—ì„œëŠ” ì´ íŒë‹¨ í•¨ìˆ˜ë¥¼ CI íŒŒì´í”„ë¼ì¸ í˜¹ì€ ë°°í¬ ê²Œì´íŠ¸ì™€ ì—°ê²°í•´ ì¸ê°„ ì˜ì‚¬ê²°ì •ì˜ í¸ì°¨ë¥¼ ì¤„ì¼ ìˆ˜ ìˆë‹¤. ë˜í•œ ì£¼ ë‹¨ìœ„ë¡œ íšŒê³  í…œí”Œë¦¿ì„ ê³ ì •í•˜ë©´ íŒ€ ê°„ ë…¼ìŸì´ ê°ì •ì´ ì•„ë‹ˆë¼ ë°ì´í„° ì¤‘ì‹¬ìœ¼ë¡œ ìˆ˜ë ´í•œë‹¤. ê²°êµ­ '{title}' ê°™ì€ ì´ìŠˆë¥¼ ì˜ ë‹¤ë£¨ëŠ” íŒ€ì€ ê¸°ìˆ  íŠ¸ë Œë“œë¥¼ ì†Œë¹„í•˜ëŠ” íŒ€ì´ ì•„ë‹ˆë¼, íŠ¸ë Œë“œë¥¼ ë‚´ë¶€ ì‹¤í–‰ ì²´ê³„ë¡œ ë²ˆì—­í•˜ëŠ” íŒ€ì´ë‹¤.",
        1200,
    )

    tips = section_exact(
        "## ì‹¤ì „ íŒ\n\n1) ì œëª©ì„ ë³µì‚¬í•˜ì§€ ë§ê³  ë¬¸ì œë¥¼ ì¬ì •ì˜í•˜ë¼: ì™¸ë¶€ ì´ìŠˆì˜ ë¬¸ì¥ ê·¸ëŒ€ë¡œ íšŒì˜ì— ì˜¬ë¦¬ë©´ í•´ê²°ì±…ì´ ì¶”ìƒí™”ëœë‹¤. ìš°ë¦¬ ì œí’ˆì˜ KPI ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì¥ì„ ë‹¤ì‹œ ì¨ì•¼ í•œë‹¤.\n2) ë°°í¬ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ 6ê°œ ì´í•˜ë¡œ ìœ ì§€í•˜ë¼: í•­ëª©ì´ ë§ì„ìˆ˜ë¡ ì‹¤ì œë¡œëŠ” ì•„ë¬´ë„ ì§€í‚¤ì§€ ì•ŠëŠ”ë‹¤. ì§€ì—°ì‹œê°„, ì˜¤ë¥˜ìœ¨, ì „í™˜ìœ¨, ë¡¤ë°± í”Œëœ, ë‹´ë‹¹ì, ê³µì§€ ë¬¸êµ¬ ì •ë„ë©´ ì¶©ë¶„í•˜ë‹¤.\n3) ë¡œê·¸ ìŠ¤í‚¤ë§ˆë¥¼ ë¨¼ì € ê³ ì •í•˜ë¼: ì´ë²¤íŠ¸ ì´ë¦„ì´ ë§¤ë²ˆ ë‹¬ë¼ì§€ë©´ ì–´ë–¤ ë¶„ì„ë„ ì‹ ë¢°í•  ìˆ˜ ì—†ë‹¤. ìµœì†Œ í•„ë“œ(user_id, event, ts, variant)ë¥¼ ê°•ì œí•˜ë¼.\n4) ì»¤ë®¤ë‹ˆí‹° ë°˜ì‘ì€ ì°¸ê³  ìë£Œì¼ ë¿ ì˜ì‚¬ê²°ì • ê·¼ê±°ê°€ ì•„ë‹ˆë‹¤: Reddit ë°˜ì‘ì€ ë¹ ë¥´ì§€ë§Œ í‘œë³¸ í¸í–¥ì´ í¬ë‹¤. ë‚´ë¶€ ì½”í˜¸íŠ¸ ë°ì´í„°ë¡œ ë°˜ë“œì‹œ êµì°¨ê²€ì¦í•˜ë¼.",
        300,
    )

    ending = section_exact(
        f"## ë§ˆë¬´ë¦¬\n\n'{title}'ëŠ” ë‹¨ìˆœí•œ í™”ì ¯ê±°ë¦¬ê°€ ì•„ë‹ˆë¼ ì œí’ˆ íŒ€ì˜ ì‹¤í–‰ í’ˆì§ˆì„ ì‹œí—˜í•˜ëŠ” ë¦¬íŠ¸ë¨¸ìŠ¤ë‹¤. í•µì‹¬ì€ íŠ¸ë Œë“œë¥¼ ë¹¨ë¦¬ ì•„ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì‹ í˜¸ë¥¼ êµ¬ì¡°í™”í•´ íŒ€ì˜ ë£¨í‹´ìœ¼ë¡œ ë§Œë“œëŠ” ë° ìˆë‹¤. ì˜¤ëŠ˜ ì†Œê°œí•œ ë¶„ì„ í”„ë ˆì„ê³¼ ì½”ë“œ ìŠ¤ë‹ˆí«, ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ê·¸ëŒ€ë¡œ ë³µì œí•´ë„ ì¶©ë¶„íˆ ì²« ì£¼ ì‹¤í—˜ì„ ì‹œì‘í•  ìˆ˜ ìˆë‹¤. ë‹¤ìŒ ê¸€ì—ì„œëŠ” ì‹¤ì œ ìš´ì˜ í™˜ê²½ì—ì„œ ì‹¤íŒ¨í–ˆë˜ ì¼€ì´ìŠ¤ë¥¼ ë³µê¸°í•˜ë©°, ì–´ë–¤ ì§€í‘œë¥¼ ë¨¼ì € ë²„ë ¤ì•¼ í•˜ëŠ”ì§€ë„ ë‹¤ë¤„ë³´ê² ë‹¤.",
        200,
    )

    content = "\n\n".join([intro, body, tips, ending])
    if len(content) < 2000:
        content += "\n\n" + "ì¶”ê°€ ì¸ì‚¬ì´íŠ¸: ì‹ í˜¸ í•´ì„ì˜ ì¼ê´€ì„±ì„ ìœ„í•´ ë¬¸ì„œí™”ëœ ì˜ì‚¬ê²°ì • ê·œì¹™ì„ ìœ ì§€í•˜ë¼." * 10
    return content


try:
    new_id = int(os.environ["NEW_ID"])
    title = os.environ["REDDIT_TITLE"].strip()
    date = os.environ["DATE"]
    image_url = os.environ["IMAGE_URL"]
    slug = os.environ["SLUG"]

    with open("posts.json", "r", encoding="utf-8") as f:
        data = json.load(f)

    content = build_content(title)

    new_post = {
        "id": new_id,
        "title": title,
        "category": "tech",
        "date": date,
        "image": image_url,
        "excerpt": make_excerpt(title),
        "content": content,
        "tags": ["Reddit", "ê¸°ìˆ ", "ê°œë°œ", "íŠ¸ë Œë“œ", "ì‹¤ì „", "auto"],
        "slug": slug,
        "image_variants": [],
    }

    data["posts"].insert(0, new_post)

    with open("posts.json", "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    print(f"ì„±ê³µ: id={new_id}, title={title}, chars={len(content)}, excerpt_chars={len(new_post['excerpt'])}")
except Exception as e:
    print(f"ì—ëŸ¬: {e}", file=sys.stderr)
    sys.exit(1)
PYTHON_SCRIPT

    echo "âœ… posts.json ì—…ë°ì´íŠ¸ ì™„ë£Œ" | tee -a "$LOG_FILE"
fi

# ===== 5. Git ì²˜ë¦¬ =====
echo "ğŸš€ Git ì²˜ë¦¬ ì¤‘..." | tee -a "$LOG_FILE"

git add auto-content-rss.sh
git commit -m "Improve RSS auto content generation quality" 2>> "$LOG_FILE" \
    && echo "âœ… ì»¤ë°‹ ì™„ë£Œ" | tee -a "$LOG_FILE" \
    || echo "âš ï¸ ì»¤ë°‹ ì—†ìŒ(ë³€ê²½ì‚¬í•­ ì—†ìŒ ë˜ëŠ” ì»¤ë°‹ ì‹¤íŒ¨)" | tee -a "$LOG_FILE"

# ê¸°ì¡´ ë™ì‘ ìœ ì§€: push ì‹œë„
if git push origin main 2>> "$LOG_FILE"; then
    echo "âœ… í‘¸ì‹œ ì„±ê³µ" | tee -a "$LOG_FILE"
else
    echo "âš ï¸ í‘¸ì‹œ ì‹¤íŒ¨ (ë„¤íŠ¸ì›Œí¬/ê¶Œí•œ í™˜ê²½ í™•ì¸ í•„ìš”)" | tee -a "$LOG_FILE"
fi

echo "âœ… ì™„ë£Œ! ($DATETIME)" | tee -a "$LOG_FILE"
echo "ë¡œê·¸: $LOG_FILE"
